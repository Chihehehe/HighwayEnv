{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Box(-1.0, 1.0, (2,), float32)\n",
      "Action space shape: (2,)\n",
      "Action space sample: [-0.4026297 -0.6026099]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
    "import logging\n",
    "\n",
    "# Enable more verbose logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Create the environment\n",
    "env = gym.make(\"highway-v1\")\n",
    "\n",
    "# Configure with explicit continuous action space parameters\n",
    "env.unwrapped.configure({\n",
    "    \"action\": {\n",
    "        \"type\": \"ContinuousAction\",\n",
    "        \"acceleration_range\": [-5.0, 5.0],  # Set explicit acceleration range\n",
    "        \"steering_range\": [-np.pi/4, np.pi/4],  # Set explicit steering range\n",
    "    },\n",
    "    # Simplify the environment for easier learning\n",
    "    \"vehicles_count\": 50,\n",
    "    \"duration\": 40,\n",
    "    \"simulation_frequency\": 15,\n",
    "    \"policy_frequency\": 1,\n",
    "})\n",
    "\n",
    "# Reset to apply configuration\n",
    "obs = env.reset()\n",
    "\n",
    "print(f\"Action space: {env.action_space}\")\n",
    "print(f\"Action space shape: {env.action_space.shape}\")\n",
    "print(f\"Action space sample: {env.action_space.sample()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_highway_tensorboard/PPO_1_10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.5      |\n",
      "|    ep_rew_mean     | 0.11     |\n",
      "| time/              |          |\n",
      "|    fps             | 3        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 534      |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a611a99820>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Vectorize the environment\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "# env = VecMonitor(env)\n",
    "\n",
    "# Configure PPO for continuous action spaces\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,  # Increase steps per update\n",
    "    batch_size=64,\n",
    "    n_epochs=10,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.0,  # Reduce entropy for more stable learning\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./ppo_highway_tensorboard/\"\n",
    ")\n",
    "\n",
    "# # Try a very small number of steps first to catch early errors\n",
    "# try:\n",
    "#     print(\"Starting learning...\")\n",
    "#     model.learn(total_timesteps=100, log_interval=1)\n",
    "#     print(\"First 100 steps completed, continuing...\")\n",
    "    \n",
    "#     # If that works, continue with more steps\n",
    "#     model.learn(total_timesteps=10000, log_interval=10, tb_log_name=\"PPO_highway\")\n",
    "#     print(\"Training completed successfully!\")\n",
    "    \n",
    "#     # Save the model\n",
    "#     model.save(\"ppo_highway_continuous\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Error during training: {e}\")\n",
    "#     import traceback\n",
    "#     traceback.print_exc()\n",
    "model.learn(total_timesteps=2000,tb_log_name = 'PPO_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_highway_tensorboard/PPO_1_10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.49     |\n",
      "|    ep_rew_mean     | 0.136    |\n",
      "| time/              |          |\n",
      "|    fps             | 4        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 497      |\n",
      "|    total_timesteps | 6144     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a611a99820>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000,tb_log_name = 'PPO_1', reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_highway_tensorboard/PPO_1_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 139      |\n",
      "|    ep_rew_mean     | 101      |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 38964    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 143         |\n",
      "|    ep_rew_mean          | 107         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 41012       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007371155 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.06        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    std                  | 0.749       |\n",
      "|    value_loss           | 21.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 148         |\n",
      "|    ep_rew_mean          | 113         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 43060       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009440666 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.22       |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00815    |\n",
      "|    std                  | 0.741       |\n",
      "|    value_loss           | 17          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a60ffe9a30>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000,tb_log_name = 'PPO_1', reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_highway_tensorboard/PPO_1_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 155      |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 45108    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 163         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 47156       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009458161 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.00449     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.612       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00771    |\n",
      "|    std                  | 0.711       |\n",
      "|    value_loss           | 2.41        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 177          |\n",
      "|    ep_rew_mean          | 138          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 12           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 479          |\n",
      "|    total_timesteps      | 49204        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142627815 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.331        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.0104      |\n",
      "|    std                  | 0.696        |\n",
      "|    value_loss           | 1.6          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a60ffe9a30>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000,tb_log_name = 'PPO_1', reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_highway_tensorboard/PPO_1_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 160      |\n",
      "|    total_timesteps | 51252    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 193         |\n",
      "|    ep_rew_mean          | 153         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 53300       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012153389 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.31        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    std                  | 0.668       |\n",
      "|    value_loss           | 0.937       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 196         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 55348       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012302945 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.216       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00799    |\n",
      "|    std                  | 0.654       |\n",
      "|    value_loss           | 0.68        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a60ffe9a30>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000,tb_log_name = 'PPO_1', reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_highway_tensorboard/PPO_1_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 160      |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 158      |\n",
      "|    total_timesteps | 57396    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 321         |\n",
      "|    total_timesteps      | 59444       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018581659 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0982      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.631       |\n",
      "|    value_loss           | 0.309       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 198         |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 61492       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008265318 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.157       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0582      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00746    |\n",
      "|    std                  | 0.627       |\n",
      "|    value_loss           | 0.47        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a60ffe9a30>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000,tb_log_name = 'PPO_1', reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppo_highway_tensorboard/PPO_1_8\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 158      |\n",
      "| time/              |          |\n",
      "|    fps             | 12       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 157      |\n",
      "|    total_timesteps | 69684    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 189         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 71732       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009612122 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | -0.0881     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 0.6         |\n",
      "|    value_loss           | 6.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 12          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 480         |\n",
      "|    total_timesteps      | 73780       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009050683 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0754      |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    std                  | 0.592       |\n",
      "|    value_loss           | 0.21        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a60ffe9a30>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=5000,tb_log_name = 'PPO_1', reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Clear the previous frame\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m       \u001b[38;5;66;03m# Display the current frame\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Check if the episode is done\u001b[39;00m\n\u001b[0;32m     29\u001b[0m done \u001b[38;5;241m=\u001b[39m truncated\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\formatters.py:182\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    180\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\formatters.py:226\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    345\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\pylabtools.py:170\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    168\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 170\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\backend_bases.py:2175\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2172\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[0;32m   2173\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[0;32m   2174\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2175\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\figure.py:3162\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3159\u001b[0m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3162\u001b[0m     \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3165\u001b[0m     renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3166\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\axes\\_base.py:3143\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[0;32m   3141\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[1;32m-> 3143\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3146\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:653\u001b[0m, in \u001b[0;36m_ImageBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    651\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im, trans)\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 653\u001b[0m     im, l, b, trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_magnification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m im \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    656\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mdraw_image(gc, l, b, im)\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:952\u001b[0m, in \u001b[0;36mAxesImage.make_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    949\u001b[0m transformed_bbox \u001b[38;5;241m=\u001b[39m TransformedBbox(bbox, trans)\n\u001b[0;32m    950\u001b[0m clip \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_box() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mbbox) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_clip_on()\n\u001b[0;32m    951\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox)\n\u001b[1;32m--> 952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_image\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed_bbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmagnification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munsampled\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munsampled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:567\u001b[0m, in \u001b[0;36m_ImageBase._make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    565\u001b[0m         output_alpha \u001b[38;5;241m=\u001b[39m _resample(  \u001b[38;5;66;03m# resample alpha channel\u001b[39;00m\n\u001b[0;32m    566\u001b[0m             \u001b[38;5;28mself\u001b[39m, A[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m], out_shape, t, alpha\u001b[38;5;241m=\u001b[39malpha)\n\u001b[1;32m--> 567\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# resample rgb channels\u001b[39;49;00m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_rgb_to_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m     output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m=\u001b[39m output_alpha  \u001b[38;5;66;03m# recombine rgb and alpha\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;66;03m# output is now either a 2D array of normed (int or float) data\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;66;03m# or an RGBA array of re-sampled input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\quynh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\image.py:208\u001b[0m, in \u001b[0;36m_resample\u001b[1;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     resample \u001b[38;5;241m=\u001b[39m image_obj\u001b[38;5;241m.\u001b[39mget_resample()\n\u001b[1;32m--> 208\u001b[0m \u001b[43m_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_interpd_\u001b[49m\u001b[43m[\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m                \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m                \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimage_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_filternorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m                \u001b[49m\u001b[43mimage_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_filterrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "import highway_env\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# Reset the environment\n",
    "obs, info = env.reset()\n",
    "done = False\n",
    "\n",
    "# Run the simulation loop\n",
    "while not done:\n",
    "    # Sample a random action\n",
    "    #action = env.action_space.sample()\n",
    "    action, _ = model.predict(obs, deterministic=False)\n",
    "\n",
    "    # Take a step in the environment\n",
    "    obs, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    # Render the environment as an image\n",
    "    frame = env.render()\n",
    "\n",
    "    # Display the rendered frame\n",
    "    plt.imshow(frame)\n",
    "    plt.axis(\"off\")\n",
    "    clear_output(wait=True)  # Clear the previous frame\n",
    "    display(plt.gcf())       # Display the current frame\n",
    "\n",
    "    # Check if the episode is done\n",
    "    done = truncated\n",
    "\n",
    "\n",
    "# Close the environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./ppo_highway_tensorboard/PPO_1_6\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.48     |\n",
      "|    ep_rew_mean     | 0.0981   |\n",
      "| time/              |          |\n",
      "|    fps             | 4        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 511      |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1a60ff87ce0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SAC model\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=0.0003,\n",
    "    policy_kwargs=dict(net_arch=[dict(pi=[256, 256], vf=[256, 256])]),\n",
    "    batch_size=64,\n",
    "    gamma=0.9,\n",
    "    clip_range=0.2,\n",
    "    ent_coef=0.00,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"ppo_highway_tensorboard\"\n",
    ")\n",
    "\n",
    "# Train the model``\n",
    "model.learn(total_timesteps=2000,tb_log_name = 'PPO_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"PPO_highwayv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"PPO_highwayv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of test episodes\n",
    "n_episodes = 50\n",
    "\n",
    "# Exponential delay parameters\n",
    "scale = 1.2  # Mean delay\n",
    "max_delay = 2  # Maximum delay in seconds\n",
    "\n",
    "# Tracking performance metrics for both tests\n",
    "cumulative_rewards_no_delay = []\n",
    "cumulative_rewards_with_delay = []\n",
    "episode_lengths_no_delay = []\n",
    "episode_lengths_with_delay = []\n",
    "crashes_no_delay = 0\n",
    "crashes_with_delay = 0\n",
    "\n",
    "# Run testing without delay\n",
    "for episode in range(n_episodes):\n",
    "    obs, info = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    episode_length = 0\n",
    "    episode_crash = False  # Track crash per episode\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        episode_length += 1\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Check if a crash occurred\n",
    "        if info.get(\"crashed\", False):\n",
    "            episode_crash = True\n",
    "\n",
    "    cumulative_rewards_no_delay.append(total_reward)\n",
    "    episode_lengths_no_delay.append(episode_length)\n",
    "    crashes_no_delay += int(episode_crash)\n",
    "\n",
    "    print(f\"Episode {episode + 1} (No Delay): Total Reward = {total_reward:.2f}, Length = {episode_length} timesteps, Crash: {episode_crash}\")\n",
    "\n",
    "# Run testing with delay\n",
    "for episode in range(n_episodes):\n",
    "    obs, info = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    episode_length = 0\n",
    "    episode_crash = False\n",
    "\n",
    "    # Generate a random delay from an exponential distribution, capped at max_delay\n",
    "    random_delay = min(np.random.exponential(scale), max_delay)\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "        # Apply the computation delay before executing the action\n",
    "        env.unwrapped.elapse(random_delay)\n",
    "\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        episode_length += 1\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Check if a crash occurred\n",
    "        if info.get(\"crashed\", False):\n",
    "            episode_crash = True\n",
    "\n",
    "    cumulative_rewards_with_delay.append(total_reward)\n",
    "    episode_lengths_with_delay.append(episode_length)\n",
    "    crashes_with_delay += int(episode_crash)\n",
    "\n",
    "    print(f\"Episode {episode + 1} (With Delay): Delay = {random_delay:.2f}s, Total Reward = {total_reward:.2f}, Length = {episode_length} timesteps, Crash: {episode_crash}\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Compute statistics\n",
    "mean_reward_no_delay = sum(cumulative_rewards_no_delay) / n_episodes\n",
    "mean_reward_with_delay = sum(cumulative_rewards_with_delay) / n_episodes\n",
    "mean_episode_length_no_delay = sum(episode_lengths_no_delay) / n_episodes\n",
    "mean_episode_length_with_delay = sum(episode_lengths_with_delay) / n_episodes\n",
    "crash_rate_no_delay = crashes_no_delay / n_episodes\n",
    "crash_rate_with_delay = crashes_with_delay / n_episodes\n",
    "\n",
    "print(f\"\\nWithout Delay - Mean Reward: {mean_reward_no_delay:.2f}, Mean Episode Length: {mean_episode_length_no_delay:.2f}, Crash Rate: {crash_rate_no_delay:.2%}\")\n",
    "print(f\"With Delay - Mean Reward: {mean_reward_with_delay:.2f}, Mean Episode Length: {mean_episode_length_with_delay:.2f}, Crash Rate: {crash_rate_with_delay:.2%}\")\n",
    "\n",
    "# Plot the results\n",
    "episodes = range(1, n_episodes + 1)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Cumulative Reward Comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(episodes, cumulative_rewards_no_delay, marker='o', label=\"No Delay\", color='#103463')\n",
    "plt.plot(episodes, cumulative_rewards_with_delay, marker='x', label=\"With Delay\", color='#f3b6b3')\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Cumulative Reward\")\n",
    "plt.title(\"Cumulative Reward Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Episode Length Comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(episodes, episode_lengths_no_delay, marker='o', label=\"No Delay\", color='#103463')\n",
    "plt.plot(episodes, episode_lengths_with_delay, marker='x', label=\"With Delay\", color='#f3b6b3')\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Episode Length\")\n",
    "plt.title(\"Episode Length Comparison\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Define metrics\n",
    "metrics_main = [\"Mean Reward\", \"Mean Episode Length\"]\n",
    "before_delay_main = [mean_reward_no_delay, mean_episode_length_no_delay]  # Mean Reward, Episode Length (before delay)\n",
    "after_delay_main = [mean_reward_with_delay, mean_episode_length_with_delay]  # Mean Reward, Episode Length (after delay)\n",
    "\n",
    "metrics_crash = [\"Crash Rate\"]\n",
    "before_delay_crash = [crash_rate_no_delay]  # Crash Rate (before delay)\n",
    "after_delay_crash = [crash_rate_with_delay]  # Crash Rate (after delay)\n",
    "\n",
    "# Set Seaborn style\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# --- First Chart: Mean Reward & Episode Length ---\n",
    "x = np.arange(len(metrics_main))  # Label positions\n",
    "width = 0.35  # Bar width\n",
    "\n",
    "bars1 = axes[0].bar(x - width/2, before_delay_main, width, label=\"Before Delay\", color=\"#103463\")\n",
    "bars2 = axes[0].bar(x + width/2, after_delay_main, width, label=\"After Delay\", color=\"#f3b6b3\")\n",
    "\n",
    "# Labels & Title\n",
    "axes[0].set_title(\"PPO Mean Reward & Episode Length\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Values\", fontsize=12)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(metrics_main)\n",
    "axes[0].legend()\n",
    "\n",
    "# Show value labels on bars\n",
    "def add_labels(bars, ax):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # Offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "add_labels(bars1, axes[0])\n",
    "add_labels(bars2, axes[0])\n",
    "\n",
    "# --- Second Chart: Crash Rate ---\n",
    "x_crash = np.arange(len(metrics_crash))  # Label positions\n",
    "crash_width = 0.3  # Narrower bar width for crash rate\n",
    "\n",
    "bars3 = axes[1].bar(x_crash - crash_width, before_delay_crash, crash_width, label=\"Before Delay\", color=\"#103463\")\n",
    "bars4 = axes[1].bar(x_crash + crash_width, after_delay_crash, crash_width, label=\"After Delay\", color=\"#f3b6b3\")\n",
    "\n",
    "# Labels & Title\n",
    "axes[1].set_title(\"PPO Crash Rate\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Values (%)\", fontsize=12)\n",
    "axes[1].set_xticks(x_crash)\n",
    "axes[1].set_xticklabels(metrics_crash)\n",
    "axes[1].legend()\n",
    "\n",
    "# Show value labels on bars\n",
    "add_labels(bars3, axes[1])\n",
    "add_labels(bars4, axes[1])\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_with_exponential_computation_costs(scale, max_delay, n_eval_episodes=50):\n",
    "    results = []\n",
    "\n",
    "    for episode in range(n_eval_episodes):\n",
    "\n",
    "        # Generate a random delay using exponential distribution, capped at max_delay (2s)\n",
    "        random_delay = min(np.random.exponential(scale), max_delay)\n",
    "\n",
    "        obs, info = env.reset()\n",
    "\n",
    "        # Run one episode\n",
    "        total_reward = 0\n",
    "        episode_length = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            env.unwrapped.elapse(random_delay, reset_steering=True)\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            episode_length += 1\n",
    "            done = terminated or truncated\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'episode': episode + 1,\n",
    "            'computation_delay': random_delay,\n",
    "            'total_reward': total_reward,\n",
    "            'episode_length': episode_length\n",
    "        })\n",
    "\n",
    "        # Print episode results\n",
    "        print(f\"Episode {episode + 1}: Delay = {random_delay:.2f}s, \"\n",
    "              f\"Total Reward = {total_reward:.2f}, Length = {episode_length} timesteps\")\n",
    "\n",
    "        # Close the environment\n",
    "        env.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Set parameters for exponential sampling\n",
    "scale = 1.2  # Mean delay (adjustable)\n",
    "max_delay = 2  # Maximum delay capped at 2 seconds\n",
    "\n",
    "# Path to the pre-trained model\n",
    "\n",
    "# Run the evaluations\n",
    "results = evaluate_with_exponential_computation_costs(scale, max_delay, n_eval_episodes=50)\n",
    "\n",
    "# Compute mean values\n",
    "mean_reward = np.mean([r['total_reward'] for r in results])\n",
    "mean_length = np.mean([r['episode_length'] for r in results])\n",
    "\n",
    "print(f\"\\nMean Total Reward: {mean_reward:.2f}\")\n",
    "print(f\"Mean Episode Length: {mean_length:.2f} timesteps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results_pretty(results):\n",
    "    # Sort results by computation delay\n",
    "    results = sorted(results, key=lambda x: x['computation_delay'])\n",
    "\n",
    "    delays = [r['computation_delay'] for r in results]\n",
    "    rewards = [r['total_reward'] for r in results]\n",
    "    lengths = [r['episode_length'] for r in results]\n",
    "\n",
    "    # Set style\n",
    "    plt.style.use(\"tableau-colorblind10\")  # Prettier theme\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Color settings\n",
    "    reward_color = \"#103463\"   # Coral red\n",
    "    length_color = \"#9b5372\"   # Teal green\n",
    "\n",
    "    # Plot Total Reward vs Delay\n",
    "    axes[0].plot(delays, rewards, marker='o', markersize=8, linestyle='-', linewidth=2.5, color=reward_color, label='Total Reward')\n",
    "    axes[0].fill_between(delays, rewards, color=reward_color, alpha=0.15)  # Light shading for effect\n",
    "    axes[0].set_xlabel('Computation Delay (s)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Total Reward', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Total Reward vs Computation Delay', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[0].legend(fontsize=12)\n",
    "\n",
    "    # Plot Episode Length vs Delay\n",
    "    axes[1].plot(delays, lengths, marker='s', markersize=8, linestyle='-', linewidth=2.5, color=length_color, label='Episode Length')\n",
    "    axes[1].fill_between(delays, lengths, color=length_color, alpha=0.15)\n",
    "    axes[1].set_xlabel('Computation Delay (s)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Episode Length (timesteps)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Episode Length vs Computation Delay', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, linestyle='--', alpha=0.6)\n",
    "    axes[1].legend(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_results_pretty(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
